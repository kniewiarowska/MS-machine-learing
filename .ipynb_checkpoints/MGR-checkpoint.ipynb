{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d06026-edaa-4767-8a9b-2bf2b373ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza i modyfikacja danych\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ewaluacja\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_score, classification_report\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# machine learning\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "models = [DecisionTreeClassifier(class_weight='balanced'), RandomForestClassifier(class_weight='balanced'), KNeighborsClassifier(), GaussianNB(),MLPClassifier(random_state=1, max_iter=300) ]\n",
    "models_names = ['Tree', 'Random forest', 'K Neighbours', 'Naive Bayes', 'MLP']\n",
    "\n",
    "\n",
    "def read_grouped_data():\n",
    "    df = pd.read_csv('data/one_hour_data.csv')\n",
    "    return df.drop(columns=df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "def calculate_feeling_rate_distribution(df):\n",
    "    print('DATA:')\n",
    "    count = df.count()[0]\n",
    "    data = []\n",
    "    numbers = df['feeling_rate'].unique()\n",
    "    for i in numbers:\n",
    "        occur = df['feeling_rate'].value_counts()[i]\n",
    "        percent = (occur / count) * 100\n",
    "        value = round(percent, 2)\n",
    "        data.append(value)\n",
    "        print(str(i) + ' ' + str(round(percent, 2)) + '%')\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(data, labels=numbers, autopct='%1.1f%%')\n",
    "\n",
    "\n",
    "def print_df_information(df):\n",
    "    print(df.head())\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "\n",
    "\n",
    "def change_txt_data(df):\n",
    "    print(df.describe(include=['O']))\n",
    "    categoricals = list(df.select_dtypes(include=['O']).columns)\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded = encoder.fit_transform(df[categoricals])\n",
    "    train_ohe = pd.DataFrame(encoded, columns=np.hstack(encoder.categories_))\n",
    "    df = pd.concat((df, train_ohe), axis=1).drop(categoricals, axis=1)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')\n",
    "\n",
    "\n",
    "def print_balanced_accuracy(balanced_accuracy, balanced_method_name, y):\n",
    "    plt.bar(models_names, balanced_accuracy)\n",
    "    addlabels(models_names,balanced_accuracy)\n",
    "\n",
    "    #giving title to the plot\n",
    "    plt.title(balanced_method_name)\n",
    "     \n",
    "    # giving X and Y labels\n",
    "    plt.xlabel(\"Models\")\n",
    "    plt.ylabel(y)\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b2a48-7e68-49dd-9b0e-44add2e93782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_df = read_raw_data()\n",
    "train_df = read_grouped_data()\n",
    "#train_df = change_txt_data(train_df)\n",
    "Y = train_df['feeling_rate'].values\n",
    "X = train_df.drop(['feeling_rate'], axis=1).values\n",
    "\n",
    "sns.heatmap(train_df.corr(), annot=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "calculate_feeling_rate_distribution(train_df)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=71830, stratify=Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888bc3a-b8b8-49c7-87b6-0700a0d465c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_feeling_rate_distribution(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2261e0f-604b-4f7f-880d-72556b21d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "balanced = []\n",
    "accuracy = []\n",
    "f1 = []\n",
    "for model in models:\n",
    "    print(str(model))\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    #Balanced acuurancy\n",
    "    balanced_accurancy = balanced_accuracy_score(Y_test, Y_pred)\n",
    "    balanced.append(round(balanced_accurancy, 2))\n",
    "    print(balanced_accurancy)\n",
    "\n",
    "    #Clasification report\n",
    "    report = classification_report(Y_test, Y_pred, output_dict=True)\n",
    "    accur = report['accuracy']\n",
    "    accuracy.append(round(accur, 2))\n",
    "    \n",
    "    # macro_precision =  report['macro avg']['precision'] \n",
    "    # macro_recall = report['macro avg']['recall']    \n",
    "    macro_f1 = report['macro avg']['f1-score']\n",
    "    f1.append(round(macro_f1, 2))\n",
    "    \n",
    "    #metric = [weight_accuracy, macro_precision, macro_recall, macro_f1]\n",
    "    #metrics.append(metric)\n",
    "\n",
    "    #Confiusion Matrix\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "    disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273f97f-d4e7-46d1-977b-953d856cf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(f1, 'F1', 'F1 [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d454c0-b467-4e8d-9c86-cea687c5a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(accuracy, 'Accuracy', 'Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf52760-9307-4f5d-868d-47cfb57a3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(balanced, 'Balanced Accuracy',  'Balanced Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe503666-e780-43ac-8368-bbd4b535a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMBALANCED DATA\n",
    "#USAGE OF RANDOM OVER SAMPLER\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, Y_resampled = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "balanced_random_over_sampler = []\n",
    "\n",
    "for model in models:\n",
    "    print(str(model))\n",
    "    model.fit(X_resampled, Y_resampled)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    #Balanced acuurancy\n",
    "    balanced_accurancy = balanced_accuracy_score(Y_test, Y_pred)\n",
    "    balanced_random_over_sampler.append(round(balanced_accurancy, 2))\n",
    "    print(balanced_accurancy)\n",
    "\n",
    "    #Clasification report\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "    #Confiusion Matrix\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "    disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0dae0a-321d-4ca6-8393-86ab46a2ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(balanced_random_over_sampler, 'RandomOverSampler',  'Balanced Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e152d-94e4-4ef0-b4c1-e5a83b144a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "\n",
    "X_resampled, Y_resampled = SMOTE().fit_resample(X_train, Y_train)\n",
    "balanced_smote = []\n",
    "\n",
    "for model in models:\n",
    "    print(str(model))\n",
    "    model.fit(X_resampled, Y_resampled)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    #Balanced acuurancy\n",
    "    balanced_accurancy = balanced_accuracy_score(Y_test, Y_pred)\n",
    "    balanced_smote.append(round(balanced_accurancy, 2))\n",
    "    print(balanced_accurancy)\n",
    "\n",
    "    #Clasification report\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "    #Confiusion Matrix\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "    disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30b438-8cce-462f-a937-284a49de1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(balanced_smote, 'SMOTE', 'Balanced Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc650b7-9ddf-4644-b94f-516a1d0410d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN\n",
    "\n",
    "X_resampled, Y_resampled = ADASYN().fit_resample(X_train, Y_train)\n",
    "balanced_adasyn = []\n",
    "\n",
    "for model in models:\n",
    "    print(str(model))\n",
    "    model.fit(X_resampled, Y_resampled)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    #Balanced acuurancy\n",
    "    balanced_accurancy = balanced_accuracy_score(Y_test, Y_pred)\n",
    "    balanced_adasyn.append(round(balanced_accurancy, 2))\n",
    "    print(balanced_accurancy)\n",
    "\n",
    "    #Clasification report\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "    #Confiusion Matrix\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "    disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6270575-91b9-446f-b77c-b35cd0dc3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(balanced_adasyn, 'ADASYN', 'Balanced Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b77fe4-0bc7-45df-986c-d0ef03e23bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_bbc = []\n",
    "for model in models:\n",
    "    bbc = BalancedBaggingClassifier(base_estimator=model,\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    " \n",
    "    bbc.fit(X_resampled, Y_resampled)\n",
    "    Y_pred = bbc.predict(X_test)\n",
    "\n",
    "    #Balanced acuurancy\n",
    "    balanced_accurancy = balanced_accuracy_score(Y_test, Y_pred)\n",
    "    balanced_bbc.append(round(balanced_accurancy, 2))\n",
    "    print(balanced_accurancy)\n",
    "\n",
    "    #Clasification report\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "    #Confiusion Matrix\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f27d8a-4c68-498f-bd29-bede81f55e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_balanced_accuracy(balanced_bbc, 'BalancedBaggingClassifier', 'Balanced Accuracy [%]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c148d8c-86b1-4c87-9753-ad36697c0b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c711c7d-b61d-4614-bfe9-fa7a194f9dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
